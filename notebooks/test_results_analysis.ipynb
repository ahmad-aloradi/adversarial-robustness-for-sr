{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from speechbrain.utils.metric_stats import EER\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy\n",
    "\n",
    "sys.path.append('../.')\n",
    "from src.modules.metrics.metrics import VerificationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = '2025-02-15_22-03-15' # 2025-02-02_22-12-58, 2025-02-09_01-18-15 2025-02-12_14-13-10 2025-02-15_22-03-15\n",
    "model_exp = Path(f'/home.local/aloradi/logs/train/runs/{model_filename}')\n",
    "eval_test = True\n",
    "\n",
    "scores_csv_file = 'test_scores.csv' if eval_test else'valid_scores.csv'\n",
    "data_df_file = 'test.csv' if eval_test else'dev.csv'\n",
    "\n",
    "tmp = list(model_exp.rglob(f'*/{scores_csv_file}'))\n",
    "assert len(tmp) == 1, f'Expected one file called test_scores.csv, found: {len(tmp)}'\n",
    "scores_path = tmp[0]\n",
    "\n",
    "df = pd.read_csv(f'{scores_path}')\n",
    "df_test = pd.read_csv(f'{str(model_exp / f\"vpc2025_artifacts/{data_df_file}\")}', sep=\"|\")\n",
    "\n",
    "df['rel_filepath'] = df['audio_path'].apply(lambda x: x.split('vpc2025_official/')[-1])\n",
    "df = df.merge(df_test[['speaker_id', 'rel_filepath', 'gender', 'recording_duration', 'text']], on='rel_filepath', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radar_plot(eer_results_speaker,\n",
    "                      output_path,\n",
    "                      title=\"Speaker-specific EER\",\n",
    "                      description=\"Equal Error Rate (EER) across different speakers\"):\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.6, 0.8], polar=True)\n",
    "    \n",
    "    labels = list(eer_results_speaker.keys())\n",
    "    values = list(eer_results_speaker.values())\n",
    "    labels = list(eer_results_speaker.keys())\n",
    "    values = list(eer_results_speaker.values())\n",
    "    num_vars = len(labels)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    \n",
    "    values += values[:1]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax.plot(angles, values, color='#FF6B6B', linewidth=2, marker='o', \n",
    "           markersize=8, label='EER Values')\n",
    "    \n",
    "    ax.grid(color='gray', alpha=0.2, linestyle='--', linewidth=1)\n",
    "    ax.set_ylim(0, max(values) * 1.2)\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(labels, fontsize=10, fontweight='bold')\n",
    "    \n",
    "    for i in range(num_vars):\n",
    "        angle_rad = angles[i]\n",
    "        angle_deg = angle_rad * 180 / np.pi\n",
    "        \n",
    "        if angle_deg > 90 and angle_deg < 270:\n",
    "            rotation = angle_deg + 180\n",
    "        else:\n",
    "            rotation = angle_deg\n",
    "            \n",
    "        ax.text(angle_rad, values[i] + max(values) * 0.1,\n",
    "                f'{values[i]:.2f}',\n",
    "                ha='center', va='center',\n",
    "                rotation=rotation,\n",
    "                fontsize=9,\n",
    "                bbox=dict(facecolor='white', \n",
    "                         edgecolor='none',\n",
    "                         alpha=0.8,\n",
    "                         pad=2))\n",
    "    \n",
    "    plt.title(title, pad=20, fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "    plt.savefig(output_path, \n",
    "                dpi=300, \n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0.5,\n",
    "                format='png',\n",
    "                transparent=True)\n",
    "    plt.close()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute gender/speaker metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gender_metrics(df: pd.DataFrame) -> Tuple[Dict, Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Compute verification metrics for each gender.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['gender', score', 'label']\n",
    "    \n",
    "    Returns:\n",
    "        gender_metrics: Dict of metrics per gender\n",
    "        gender_curves: Dict of curve data per gender\n",
    "        gender_eer: Dict of EER values per gender\n",
    "    \"\"\"\n",
    "    gender_metrics = {}\n",
    "    gender_curves = {}\n",
    "    gender_eer = {}\n",
    "    metric = VerificationMetrics()\n",
    "    \n",
    "    for gender in df['gender'].unique():\n",
    "        metric.reset()\n",
    "        gender_data = df[df['gender'] == gender]\n",
    "        \n",
    "        # Compute metrics\n",
    "        metric.update(\n",
    "            torch.from_numpy(gender_data['score'].values),\n",
    "            torch.from_numpy(gender_data['label'].values)\n",
    "        )\n",
    "        metrics = metric.compute()\n",
    "        \n",
    "        # Store results\n",
    "        gender_metrics[gender] = metrics\n",
    "        gender_curves[gender] = {\n",
    "            k: v.detach().cpu().numpy() \n",
    "            for k, v in metric._curve_data.items()\n",
    "        }\n",
    "        gender_eer[gender] = metrics['eer']\n",
    "        \n",
    "    return gender_metrics, gender_curves, gender_eer\n",
    "\n",
    "\n",
    "def plot_gender_det_curves(gender_curves: Dict, gender_metrics: Dict, eps: float = 1e-8) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot DET curves for multiple speakers.\n",
    "    \n",
    "    Args:\n",
    "        gender_curves: Dict of curve data per speaker\n",
    "        gender_metrics: Dict of metrics per speaker\n",
    "        eps: Small value for numerical stability\n",
    "    \n",
    "    Returns:\n",
    "        Matplotlib figure\n",
    "    \"\"\"\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Get sorted genders for consistent ordering\n",
    "    genders = sorted(gender_curves.keys())\n",
    "    \n",
    "    # Define fixed colors for consistency\n",
    "    GENDER_COLORS = {'female': '#FF69B4','male': '#4169E1'}\n",
    "    \n",
    "    # Plot each speaker's curve\n",
    "    mean_eer = []\n",
    "    for gender in genders:\n",
    "        curves = gender_curves[gender]\n",
    "        metrics = gender_metrics[gender]\n",
    "        \n",
    "        far = np.maximum(curves['far'], eps)\n",
    "        frr = np.maximum(curves['frr'], eps)\n",
    "        eer = metrics['eer']\n",
    "        mean_eer.append(eer)\n",
    "        \n",
    "        ax.plot(far, frr, '-', color=GENDER_COLORS.get(gender, 'gray'), alpha=0.5, linewidth=1, label=f'{gender} (EER: {eer:.3f})')\n",
    "    \n",
    "    # Plot mean EER point for visual clarity\n",
    "    mean_eer_value = np.mean(mean_eer)\n",
    "    ax.plot(mean_eer_value, mean_eer_value, 'ko', markersize=8, label=f'Mean EER: {mean_eer_value:.3f}')\n",
    "    \n",
    "    # Plot diagonal\n",
    "    ax.plot([eps, 1], [eps, 1], 'k--', alpha=0.3, linewidth=1)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('False Acceptance Rate (FAR)')\n",
    "    ax.set_ylabel('False Rejection Rate (FRR)')\n",
    "    ax.set_title('Detection Error Tradeoff (DET) Curves by Gender')\n",
    "    ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=True, fancybox=False, edgecolor='black')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def compute_speaker_metrics(df: pd.DataFrame) -> Tuple[Dict, Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Compute verification metrics for each speaker.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns ['enrollment_id', 'speaker_id', 'score', 'label']\n",
    "    \n",
    "    Returns:\n",
    "        speaker_metrics: Dict of metrics per speaker\n",
    "        speaker_curves: Dict of curve data per speaker\n",
    "        speaker_eer: Dict of EER values per speaker ID\n",
    "    \"\"\"\n",
    "    speaker_metrics = {}\n",
    "    speaker_curves = {}\n",
    "    speaker_eer = {}\n",
    "    metric = VerificationMetrics()\n",
    "    \n",
    "    for speaker in df['enrollment_id'].unique():\n",
    "        metric.reset()\n",
    "        speaker_data = df[df['speaker_id'] == speaker]\n",
    "        \n",
    "        # Compute metrics\n",
    "        metric.update(\n",
    "            torch.from_numpy(speaker_data['score'].values),\n",
    "            torch.from_numpy(speaker_data['label'].values)\n",
    "        )\n",
    "        metrics = metric.compute()\n",
    "        \n",
    "        # Store results\n",
    "        speaker_metrics[speaker] = metrics\n",
    "        speaker_curves[speaker] = {\n",
    "            k: v.detach().cpu().numpy() \n",
    "            for k, v in metric._curve_data.items()\n",
    "        }\n",
    "        speaker_eer[speaker.split('_')[-1]] = metrics['eer']\n",
    "        \n",
    "    return speaker_metrics, speaker_curves, speaker_eer\n",
    "\n",
    "\n",
    "def plot_speaker_det_curves(speaker_curves: Dict, \n",
    "                            speaker_metrics: Dict,\n",
    "                            eps: float = 1e-8,\n",
    "                            max_speakers: int = None) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot DET curves for multiple speakers.\n",
    "    \n",
    "    Args:\n",
    "        speaker_curves: Dict of curve data per speaker\n",
    "        speaker_metrics: Dict of metrics per speaker\n",
    "        eps: Small value for numerical stability\n",
    "        max_speakers: Maximum number of speakers to plot (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        Matplotlib figure\n",
    "    \"\"\"\n",
    "    plt.style.use('seaborn-v0_8-paper')\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Select speakers to plot\n",
    "    speakers = sorted(speaker_curves.keys())\n",
    "    if max_speakers:\n",
    "        speakers = speakers[:max_speakers]\n",
    "    \n",
    "    # Get color map for speakers\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(speakers)))\n",
    "    \n",
    "    # Plot each speaker's curve\n",
    "    mean_eer = []\n",
    "    for speaker, color in zip(speakers, colors):\n",
    "        curves = speaker_curves[speaker]\n",
    "        metrics = speaker_metrics[speaker]\n",
    "        \n",
    "        far = np.maximum(curves['far'], eps)\n",
    "        frr = np.maximum(curves['frr'], eps)\n",
    "        eer = metrics['eer']\n",
    "        mean_eer.append(eer)\n",
    "        \n",
    "        ax.plot(far, frr, '-', color=color, alpha=0.5, linewidth=1,\n",
    "               label=f'Speaker {speaker.split(\"_\")[-1]} (EER: {eer:.3f})')\n",
    "    \n",
    "    # Plot mean EER point for visual clarity\n",
    "    mean_eer_value = np.mean(mean_eer)\n",
    "    ax.plot(mean_eer_value, mean_eer_value, 'ko', markersize=8,\n",
    "           label=f'Mean EER: {mean_eer_value:.3f}')\n",
    "    \n",
    "    # Plot diagonal\n",
    "    ax.plot([eps, 1], [eps, 1], 'k--', alpha=0.3, linewidth=1)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('False Acceptance Rate (FAR)')\n",
    "    ax.set_ylabel('False Rejection Rate (FRR)')\n",
    "    ax.set_title('Detection Error Tradeoff (DET) Curves by Speaker')\n",
    "    ax.grid(True, which='both', linestyle='--', alpha=0.3)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', \n",
    "             frameon=True, fancybox=False, edgecolor='black')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_speaker_results(df: pd.DataFrame, output_path: str, max_speakers: int = None):\n",
    "    \"\"\"\n",
    "    Analyze and plot verification results from scores file.\n",
    "    \n",
    "    Args:\n",
    "        df: CSV dataframe\n",
    "        output_path: path to save the figure\n",
    "        max_speakers: Maximum number of speakers to plot\n",
    "    \"\"\"\n",
    "    # Compute metrics\n",
    "    speaker_metrics, speaker_curves, speaker_eer = compute_speaker_metrics(df)\n",
    "    \n",
    "    # Plot DET curves\n",
    "    det_fig = plot_speaker_det_curves(\n",
    "        speaker_curves, \n",
    "        speaker_metrics,\n",
    "        max_speakers=max_speakers\n",
    "    )\n",
    "    plt.savefig(output_path,\n",
    "                dpi=300,\n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0.5,\n",
    "                format='png',\n",
    "                transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    return det_fig, speaker_metrics, speaker_eer\n",
    "\n",
    "\n",
    "def analyze_gender_results(df: pd.DataFrame, output_path: str):\n",
    "    \"\"\"\n",
    "    Analyze and plot verification results from scores file.\n",
    "    \n",
    "    Args:\n",
    "        df: CSV dataframe\n",
    "        output_path: path to save the figure\n",
    "        max_speakers: Maximum number of speakers to plot\n",
    "    \"\"\"\n",
    "    # Compute metrics\n",
    "    gender_metrics, gender_curves, gender_eer = compute_gender_metrics(df)\n",
    "    \n",
    "    # Plot DET curves\n",
    "    det_fig = plot_gender_det_curves(gender_curves, gender_metrics)\n",
    "    \n",
    "    plt.savefig(output_path,\n",
    "                dpi=300,\n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0.5,\n",
    "                format='png',\n",
    "                transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    return det_fig, gender_metrics, gender_eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_analysis_header(anon_model: str):\n",
    "    header = f\"\"\"\n",
    "    <div style=\"background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
    "        <h3 style=\"color: #2c3e50; margin: 0; text-align: center;\">\n",
    "            Analyzing Anonymization System: {anon_model}\n",
    "        </h3>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(header))\n",
    "\n",
    "def print_analysis_results(speaker_eer, gender_eer):\n",
    "    results = f\"\"\"\n",
    "    <div style=\"background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;\">\n",
    "        <h4 style=\"color: #2c3e50; margin: 0 0 10px 0;\">Results Summary:</h4>\n",
    "        <p style=\"margin: 5px 0; color: #34495e;\">\n",
    "            <b>Speaker Results:</b><br>\n",
    "            Mean EER: {np.mean(list(speaker_eer.values())):.3f} ± {np.std(list(speaker_eer.values())):.3f}\n",
    "        </p>\n",
    "        <p style=\"margin: 5px 0; color: #34495e;\">\n",
    "            <b>Gender Results:</b><br>\n",
    "            Mean EER: {np.mean(list(gender_eer.values())):.3f} ± {np.std(list(gender_eer.values())):.3f}\n",
    "        </p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tot_speaker_metrics = {}\n",
    "tot_gender_metrics = {}\n",
    "results_dir = f'results/{model_filename}'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "for anon_model in df['model'].unique():\n",
    "    df_test = df[df['model'] == anon_model]\n",
    "    \n",
    "    print_analysis_header(anon_model)\n",
    "    \n",
    "    fig_speaker, speaker_metrics, speaker_eer = analyze_speaker_results(\n",
    "        df_test, output_path=f'{results_dir}/speaker_DET_{anon_model}.png', max_speakers=None)\n",
    "    fig_gender, gender_metrics, gender_eer = analyze_gender_results(\n",
    "        df_test, output_path=f'{results_dir}/gender_DET_{anon_model}.png')\n",
    "    \n",
    "    print_analysis_results(speaker_eer, gender_eer)\n",
    "    \n",
    "    # Save results as csvs\n",
    "    tot_speaker_metrics[anon_model] = pd.DataFrame.from_records(speaker_metrics).astype(float)\n",
    "    tot_gender_metrics[anon_model] = pd.DataFrame.from_records(gender_metrics).astype(float)\n",
    "    tot_speaker_metrics[anon_model].to_csv(f'{results_dir}/per_speaker_results_{anon_model}.csv')\n",
    "    tot_gender_metrics[anon_model].to_csv(f'{results_dir}/per_gender_results_{anon_model}.csv')\n",
    "\n",
    "    # Create radar plot\n",
    "    create_radar_plot(speaker_eer, output_path=f'results/speaker_eer_{anon_model}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (comfort)",
   "language": "python",
   "name": "comfort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
