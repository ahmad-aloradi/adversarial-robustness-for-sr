{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from speechbrain.utils.metric_stats import EER\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../.')\n",
    "from src.modules.metrics.metrics import SpeakerVerificationMetrics, VerificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exp = Path('/home.local/aloradi/logs/train/runs/2025-02-02_22-12-58')\n",
    "anon_model = 'B3'\n",
    "eval_test = True\n",
    "\n",
    "scores_csv_file = 'test_scores.csv' if eval_test else'valid_scores.csv'\n",
    "data_df_file = 'test.csv' if eval_test else'dev.csv'\n",
    "\n",
    "tmp = list(model_exp.rglob(f'*/{scores_csv_file}'))\n",
    "assert len(tmp) == 1, f'Expected one file called test_scores.csv, found: {len(tmp)}'\n",
    "scores_path = tmp[0]\n",
    "\n",
    "df = pd.read_csv(f'{scores_path}')\n",
    "df_test = pd.read_csv(f'{str(model_exp / f\"vpc2025_artifacts/{data_df_file}\")}', sep=\"|\")\n",
    "\n",
    "df['rel_filepath'] = df['audio_path'].str.extract(fr'({anon_model}.*)')\n",
    "df = df.merge(df_test[['speaker_id', 'rel_filepath', 'gender', 'recording_duration', 'text']], on='rel_filepath', how='left')\n",
    "\n",
    "metric = VerificationMetrics() #VerificationMetrics() SpeakerVerificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute EER for each enrollment speaker\n",
    "speakers = df['enrollment_id'].unique()\n",
    "genders = df['gender'].unique()\n",
    "eer_results_speaker = {}\n",
    "eer_results_gender = {}\n",
    "\n",
    "metric_out_speaker = {}\n",
    "speakers_figures = {}\n",
    "metric_out_gender = {'male': [], 'female': []}\n",
    "gender_figures =  {'male': [], 'female': []}\n",
    "\n",
    "\n",
    "######## Speaker-level EER (take with a pinch of salt) #########\n",
    "for speaker in speakers:\n",
    "    metric.reset()\n",
    "    speaker_data = df[df['speaker_id'] == speaker]\n",
    "    scores = speaker_data['score'].values\n",
    "    labels = speaker_data['label'].values\n",
    "    \n",
    "    metric.update(torch.from_numpy(scores), torch.from_numpy(labels))\n",
    "    metrics = metric.compute()\n",
    "    metric_out_speaker[speaker] = metrics\n",
    "#     speakers_figures[speaker] = metric.plot_curves()\n",
    "    \n",
    "    eer_results_speaker[speaker.split('_')[-1]] = metrics['eer']\n",
    "\n",
    "    \n",
    "######## Gender-level EER (Official evaluation) #########\n",
    "for gender in genders:\n",
    "    metric.reset()\n",
    "    \n",
    "    speaker_data = df[df['gender'] == gender]\n",
    "    scores = speaker_data['score'].values\n",
    "    labels = speaker_data['label'].values\n",
    "    \n",
    "    metric.update(torch.from_numpy(scores), torch.from_numpy(labels))\n",
    "    metrics = metric.compute()\n",
    "#     gender_figures[gender] = metric.plot_curves()\n",
    "    \n",
    "    metric_out_gender[gender] = metrics\n",
    "    eer_results_gender[gender] = metrics['eer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_out_speaker = pd.DataFrame.from_records(metric_out_speaker).astype(float)\n",
    "metric_out_gender = pd.DataFrame.from_records(metric_out_gender).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_out_speaker.to_csv('per_speaker_results.csv')\n",
    "metric_out_gender.to_csv('per_gender_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radar_plot(eer_results_speaker,\n",
    "                      output_path,\n",
    "                      title=\"Speaker-specific EER\",\n",
    "                      description=\"Equal Error Rate (EER) across different speakers\"):\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_axes([0.1, 0.1, 0.6, 0.8], polar=True)\n",
    "    \n",
    "    labels = list(eer_results_speaker.keys())\n",
    "    values = list(eer_results_speaker.values())\n",
    "    num_vars = len(labels)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    \n",
    "    values += values[:1]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax.plot(angles, values, color='#FF6B6B', linewidth=2, marker='o', \n",
    "           markersize=8, label='EER Values')\n",
    "    \n",
    "    ax.grid(color='gray', alpha=0.2, linestyle='--', linewidth=1)\n",
    "    ax.set_ylim(0, max(values) * 1.2)\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(labels, fontsize=10, fontweight='bold')\n",
    "    \n",
    "    for i in range(num_vars):\n",
    "        angle_rad = angles[i]\n",
    "        angle_deg = angle_rad * 180 / np.pi\n",
    "        \n",
    "        if angle_deg > 90 and angle_deg < 270:\n",
    "            rotation = angle_deg + 180\n",
    "        else:\n",
    "            rotation = angle_deg\n",
    "            \n",
    "        ax.text(angle_rad, values[i] + max(values) * 0.1,\n",
    "                f'{values[i]:.2f}',\n",
    "                ha='center', va='center',\n",
    "                rotation=rotation,\n",
    "                fontsize=9,\n",
    "                bbox=dict(facecolor='white', \n",
    "                         edgecolor='none',\n",
    "                         alpha=0.8,\n",
    "                         pad=2))\n",
    "    \n",
    "    plt.title(title, pad=20, fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1.1, 0.5))\n",
    "\n",
    "    plt.savefig(output_path, \n",
    "                dpi=300, \n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0.5,\n",
    "                format='png',\n",
    "                transparent=True)\n",
    "    plt.close()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_radar_plot(eer_results_speaker, output_path='speaker_eer.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (comfort)",
   "language": "python",
   "name": "comfort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
