{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825e9a5-a1dd-45c4-a90b-3fc597b26997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from speechbrain.augment.time_domain import DropChunk, DropFreq, AddReverb, AddNoise, DropBitResolution, SpeedPerturb\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio, display, HTML\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72141b96-1c08-4441-9f4a-949f05802cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5296a-42c8-442b-8889-b13c3ad99dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'data/voxceleb/voxceleb1_2/id00012/21Uxsk56VDQ/00001.wav'\n",
    "path2 = 'data/voxceleb/voxceleb1_2/id00012/21Uxsk56VDQ/00002.wav'\n",
    "\n",
    "audio1, sr1 = sf.read(path1)\n",
    "audio2, sr2 = sf.read(path2)\n",
    "\n",
    "assert sr1 == sr2\n",
    "sr = sr1\n",
    "\n",
    "min_len = min(len(audio1), len(audio2))\n",
    "if min_len == len(audio1):\n",
    "    audio2 = audio2[: min_len]\n",
    "else:\n",
    "    audio1 = audio1[: min_len]\n",
    "\n",
    "\n",
    "audio1 = torch.tensor(audio1).float().unsqueeze(0)\n",
    "audio2 = torch.tensor(audio2).float().unsqueeze(0)\n",
    "audio = torch.cat((audio1, audio2), dim=0)\n",
    "audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c914dc26-5942-4008-b7a2-961355c33e53",
   "metadata": {},
   "source": [
    "## DropChunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d17d3-1d72-4815-bae9-8aa925e7bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_dropper = DropChunk(drop_length_low=2000, drop_length_high=8000)\n",
    "chunk_dropped = chunk_dropper(audio, torch.tensor([1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2e79a-a72a-4ee2-834d-44c4178e1cd0",
   "metadata": {},
   "source": [
    "## DropFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98543261-25d8-4bc0-b29f-9cf89f36bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dropper = DropFreq(drop_freq_count_low=1, drop_freq_count_high=3)\n",
    "freq_dropped = freq_dropper(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f33bf93-d8ee-40ec-baef-49f7ebcf8b3a",
   "metadata": {},
   "source": [
    "## AddReverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9153a7-15eb-49a2-ab53-ca6d2d8a4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb = AddReverb('data/voxceleb/RIRS_NOISES/reverb.csv')\n",
    "reverbed = reverb(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600c8b9-14fb-4719-ba93-f8e6bf737ec9",
   "metadata": {},
   "source": [
    "## AddNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099b648-563f-4752-afa9-e77a7e8a98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisifier = AddNoise('data/voxceleb/RIRS_NOISES/noise.csv')\n",
    "noisy = noisifier(audio, lengths=torch.tensor([1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf313157-36f6-45c5-83ad-8352001746fc",
   "metadata": {},
   "source": [
    "## DropBitResolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3b8c6-8d00-41f6-863f-02effc163989",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_dropper = DropBitResolution()\n",
    "bit_dropped = bit_dropper(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc4fb0-1a60-49ab-8ddc-3d0988bb35fc",
   "metadata": {},
   "source": [
    "## SpeedPerturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76dc517-8fff-4fe0-9ea7-783467e7d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_perturber = SpeedPerturb(orig_freq=sr, speeds=[90, 110], device='cuda')\n",
    "speeded = speed_perturber(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5827e-5957-4253-8c08-01f5eec0c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns the HTML for an audio player\n",
    "def audio_player_html(audio_array, sr):\n",
    "    # Create an IPython Audio object and return its HTML representation\n",
    "    return Audio(audio_array, rate=sr)._repr_html_()\n",
    "\n",
    "# --- Example audio data ---\n",
    "# Define paths for different samples under different conditions\n",
    "audio_data = {\n",
    "    'Sample': [f\"{path1[path1.index('voxceleb1_2') + len('voxceleb1_2') + 1:]}\", \n",
    "               f\"{path2[path2.index('voxceleb1_2') + len('voxceleb1_2') + 1:]}\"\n",
    "              ],\n",
    "    'Clean': [audio[0], audio[1] ],\n",
    "    'Noisy': [noisy[0], noisy[1]],\n",
    "    'Reverberated': [reverbed[0], reverbed[1]],\n",
    "    'Frequency Dropped': [freq_dropped[0], freq_dropped[1] ],\n",
    "    'Chunks Dropped': [chunk_dropped[0], chunk_dropped[1]],\n",
    "    'Bit Dropped': [bit_dropped[0], bit_dropped[1]],\n",
    "    'Speed Pertubed': [speeded[0], speeded[1]]\n",
    "}\n",
    "\n",
    "# Build the HTML table dynamically\n",
    "headers = list(audio_data.keys())\n",
    "table_html = '<table border=\"1\" style=\"border-collapse: collapse; text-align: center;\">'\n",
    "\n",
    "# Create header row with centered headings\n",
    "table_html += '<tr>'\n",
    "for header in headers:\n",
    "    table_html += f'<th style=\"padding: 8px; text-align: center;\">{header}</th>'\n",
    "table_html += '</tr>'\n",
    "\n",
    "# Determine the number of samples (assuming all lists are the same length)\n",
    "n_samples = len(audio_data['Sample'])\n",
    "\n",
    "# Create table rows for each sample\n",
    "for i in range(n_samples):\n",
    "    row_html = '<tr>'\n",
    "    for key in headers:\n",
    "        if key == 'Sample':\n",
    "            row_html += f'<td style=\"padding: 8px;\">{audio_data[key][i]}</td>'\n",
    "        else:\n",
    "            audio_array = audio_data[key][i]\n",
    "            player_html = audio_player_html(audio_array, sr)\n",
    "            row_html += f'<td style=\"padding: 8px;\">{player_html}</td>'\n",
    "    row_html += '</tr>'\n",
    "    table_html += row_html\n",
    "\n",
    "table_html += '</table>'\n",
    "\n",
    "# Display the complete table in the Jupyter Notebook\n",
    "display(HTML(table_html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
