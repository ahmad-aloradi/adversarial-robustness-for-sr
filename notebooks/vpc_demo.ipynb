{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import base64\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "from typing import Optional, Dict, Union\n",
    "import shutil\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT_DIR = '/home/aloradi/adversarial-robustness-for-sr'\n",
    "DATA_DIR = f\"{ROOT_DIR}{os.sep}data\"\n",
    "VPC_DIR = f\"{DATA_DIR}{os.sep}vpc2025_official\"\n",
    "LIBRI_DIR =  DATA_DIR\n",
    "os.chdir(ROOT_DIR)\n",
    "\n",
    "BASE_DIR = Path('data/vpc2025_official')\n",
    "LIBRI_PATH = 'librispeech/test-clean/LibriSpeech'\n",
    "LIBRI_SETS = {\n",
    "    'TRAIN': 'train-clean-360',\n",
    "    'DEV': 'dev-clean',\n",
    "    'TEST': 'test-clean'\n",
    "}\n",
    "\n",
    "csv_name = 'test_enrolls.csv'\n",
    "WAV_COL_ID = 'enrollment_path' # 'wav_path'\n",
    "\n",
    "SETNAME = LIBRI_SETS['TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_speakers_and_utterances(df, num_speakers, num_utts_per_spk, random_seed=None):\n",
    "    \"\"\"\n",
    "    Sample a specific number of utterances from a specific number of speakers.\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame containing a speaker_id column\n",
    "        num_speakers: number of speakers to sample\n",
    "        num_utts_per_spk: number of utterances to sample per speaker\n",
    "        random_seed: random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        pandas DataFrame containing the sampled data\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # Get unique speaker IDs and check if we have enough speakers\n",
    "    unique_speakers = df['speaker_id'].unique()\n",
    "    if len(unique_speakers) < num_speakers:\n",
    "        raise ValueError(f\"Not enough speakers in dataset. Requested {num_speakers} but only found {len(unique_speakers)}\")\n",
    "    \n",
    "    # Randomly sample speakers\n",
    "    sampled_speakers = np.random.choice(unique_speakers, size=num_speakers, replace=False)\n",
    "    \n",
    "    # Initialize list to store sampled utterances\n",
    "    sampled_data = []\n",
    "    \n",
    "    # For each sampled speaker\n",
    "    for speaker in sampled_speakers:\n",
    "        # Get all utterances for this speaker\n",
    "        speaker_utts = df[df['speaker_id'] == speaker]\n",
    "        \n",
    "        # Check if we have enough utterances for this speaker\n",
    "        if len(speaker_utts) < num_utts_per_spk:\n",
    "            print(f\"Warning: Speaker {speaker} has fewer utterances ({len(speaker_utts)}) than requested ({num_utts_per_spk})\")\n",
    "            sampled_utts = speaker_utts  # Take all available utterances\n",
    "        else:\n",
    "            # Randomly sample utterances for this speaker\n",
    "            sampled_utts = speaker_utts.sample(n=num_utts_per_spk)\n",
    "        \n",
    "        sampled_data.append(sampled_utts)\n",
    "    \n",
    "    # Concatenate all sampled utterances\n",
    "    result_df = pd.concat(sampled_data, ignore_index=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vpc_data(num_utts_per_spk=3, num_speakers=9, sep=\"|\"):\n",
    "    \n",
    "    # List of directories to process (B4 and T10-2 do not follow the standard structure)\n",
    "    target_dirs = ['B3', 'B4', 'B5', 'T10-2', 'T12-5', 'T25-1', 'T8-5']\n",
    "    all_samples = []\n",
    "    \n",
    "    for counter, dir_name in enumerate(target_dirs):\n",
    "        split_name = f\"metadata\"\n",
    "        csv_path = BASE_DIR / dir_name / \"data/metadata\" / csv_name\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path, sep=sep)\n",
    "\n",
    "            # Sample the data\n",
    "            sampled_df = sample_speakers_and_utterances(\n",
    "                df, \n",
    "                num_speakers=num_speakers, \n",
    "                num_utts_per_spk=num_utts_per_spk,\n",
    "                random_seed=42  # For reproducibility\n",
    "            )\n",
    "            if counter == 0:\n",
    "                # Print statistics\n",
    "                print(f\"Original dataset size: {len(df)}\")\n",
    "                print(f\"Sampled dataset size: {len(sampled_df)}\")\n",
    "                print(f\"Number of unique speakers in sample: {sampled_df['speaker_id'].nunique()}\")\n",
    "                print(\"\\nUtterances per speaker in sample:\")\n",
    "                print(sampled_df.groupby('speaker_id').size())\n",
    "                print('=====================================\\n')\n",
    "            \n",
    "            # Add system name column\n",
    "            sampled_df['system_name'] = dir_name            \n",
    "            all_samples.append(sampled_df)\n",
    "            \n",
    "        else:\n",
    "            print(f\"Warning: Could not find CSV file for {dir_name}\")\n",
    "    \n",
    "    # Concatenate all samples\n",
    "    combined_df = pd.concat(all_samples, ignore_index=True)\n",
    "    \n",
    "    # Create LibriSpeech path column\n",
    "    combined_df['basename'] = combined_df[WAV_COL_ID].apply(lambda x: os.path.basename(x))\n",
    "    combined_df['libri_path'] = combined_df['basename'].apply(\n",
    "        lambda x: str(Path(LIBRI_PATH) / SETNAME / x.split('-')[0] / x.split('-')[1] / f'{os.path.splitext(x)[0]}.flac') \n",
    "    )\n",
    "    \n",
    "    # Made redundant by system_name\n",
    "    del combined_df['model']\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(file_path, root_dir, normalization_method='loudness', target_lufs=-23.0):\n",
    "    \"\"\"\n",
    "    Process audio file with improved loudness normalization.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the audio file relative to root_dir\n",
    "        root_dir: Root directory containing the audio files\n",
    "        normalization_method: String indicating normalization method\n",
    "            'loudness': EBU R128 loudness normalization\n",
    "            'peak': Peak normalization to [-1, 1]\n",
    "            'none': No normalization\n",
    "        target_lufs: Target loudness in LUFS (default: -23.0 LUFS for broadcast standard)\n",
    "            Common values:\n",
    "            -23.0 LUFS: EBU R128 broadcast standard\n",
    "            -16.0 LUFS: Streaming services (Spotify)\n",
    "            -14.0 LUFS: Modern streaming/YouTube\n",
    "        \n",
    "    Returns:\n",
    "        str: base64 encoded audio data with data URI scheme\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pyloudnorm as pyln\n",
    "        \n",
    "        # Properly join paths\n",
    "        full_path = os.path.join(root_dir, file_path)\n",
    "        \n",
    "        if not os.path.isfile(full_path):\n",
    "            raise ValueError(f\"Audio file not found: {full_path}\")\n",
    "            \n",
    "        # Read the WAV file\n",
    "        data, sample_rate = sf.read(full_path)\n",
    "\n",
    "        # Convert to mono if stereo\n",
    "        if len(data.shape) > 1:\n",
    "            data = np.mean(data, axis=1)\n",
    "\n",
    "        # Ensure the audio is float32 for loudnorm processing\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "        if normalization_method == 'loudness':\n",
    "            # Create BS.1770 meter\n",
    "            meter = pyln.Meter(sample_rate)  # Uses BS.1770-4 standard\n",
    "            \n",
    "            # Measure input loudness\n",
    "            input_loudness = meter.integrated_loudness(data)\n",
    "            \n",
    "            print(f\"Input loudness: {input_loudness:.1f} LUFS\")\n",
    "            \n",
    "            # Check if audio is too quiet for accurate measurement\n",
    "            if input_loudness < -70.0:\n",
    "                print(\"Warning: Input audio very quiet, measurements may be inaccurate\")\n",
    "            \n",
    "            # Normalize to target LUFS if needed\n",
    "            if abs(input_loudness - target_lufs) > 0.1:  # Only normalize if difference > 0.1 LUFS\n",
    "                data = pyln.normalize.loudness(data, input_loudness, target_lufs)\n",
    "                \n",
    "                # Verify the normalization\n",
    "                final_loudness = meter.integrated_loudness(data)\n",
    "                print(f\"Output loudness: {final_loudness:.1f} LUFS\")\n",
    "                \n",
    "            # Apply true-peak limiting to prevent clipping\n",
    "            peak = np.max(np.abs(data))\n",
    "            if peak > 1.0:\n",
    "                data = data / peak * 0.99  # Leave 0.1 dB headroom\n",
    "                print(f\"Applied true-peak limiting. Peak value: {20 * np.log10(peak):.1f} dBFS\")\n",
    "                \n",
    "        elif normalization_method == 'peak':\n",
    "            peak = np.max(np.abs(data))\n",
    "            if peak > 0:\n",
    "                data = data / peak * 0.99  # Leave 0.1 dB headroom\n",
    "                \n",
    "        elif normalization_method != 'none':\n",
    "            raise ValueError(f\"Unknown normalization method: {normalization_method}\")\n",
    "\n",
    "        # Add dither before converting to 16-bit (reduce quantization noise)\n",
    "        def apply_dither(x, bits=16):\n",
    "            \"\"\"Apply triangular dither before quantization\"\"\"\n",
    "            peak = np.max(np.abs(x))\n",
    "            if peak > 0:\n",
    "                x = x / peak  # Normalize to [-1, 1]\n",
    "            \n",
    "            # Calculate quantization step size\n",
    "            q = 2.0 ** (-bits)\n",
    "            \n",
    "            # Generate triangular dither noise\n",
    "            r = np.random.random(len(x))\n",
    "            noise = (r - np.random.random(len(x))) * q\n",
    "            \n",
    "            # Add dither and quantize\n",
    "            return (x + noise) * peak\n",
    "\n",
    "        # Apply dither and convert to 16-bit PCM\n",
    "        data = apply_dither(data)\n",
    "        data = np.int16(data * 32767)\n",
    "\n",
    "        # Use tempfile for temporary file handling\n",
    "        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:\n",
    "            temp_path = temp_file.name\n",
    "            \n",
    "        try:\n",
    "            # Write to temp file\n",
    "            wavfile.write(temp_path, sample_rate, data)\n",
    "            \n",
    "            # Read and encode\n",
    "            with open(temp_path, 'rb') as audio_file:\n",
    "                audio_data = base64.b64encode(audio_file.read()).decode('utf-8')\n",
    "                \n",
    "            return f\"data:audio/wav;base64,{audio_data}\"\n",
    "            \n",
    "        finally:\n",
    "            if os.path.exists(temp_path):\n",
    "                os.remove(temp_path)\n",
    "                \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error processing audio file {file_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_report(\n",
    "    df: pd.DataFrame,\n",
    "    enrollment_root: str,\n",
    "    libri_root: str,\n",
    "    output_dir: str = \"local\",\n",
    "    output_file: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create an HTML report with audio files from enrollment and LibriSpeech roots.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if output_file is None:\n",
    "        from datetime import datetime\n",
    "        output_file = f\"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
    "    \n",
    "    # Map columns to their root directories, audio types and display names\n",
    "    AUDIO_ROOTS = {\n",
    "        'libri_path': {'root': Path(libri_root), 'type': 'flac', 'display': 'Original'},\n",
    "        'enrollment_path': {'root': Path(enrollment_root), 'type': 'wav', 'display': 'Anonymized'}\n",
    "    }\n",
    "\n",
    "    # Map for display names of all columns\n",
    "    COLUMN_DISPLAY_NAMES = {\n",
    "        'libri_path': 'Original',\n",
    "        'enrollment_path': 'Anonymized'\n",
    "    }\n",
    "\n",
    "    def handle_audio_file(src_path: Path, root_path: Path, audio_type: str) -> tuple[Path, str]:\n",
    "        \"\"\"Copy or convert audio file as needed.\"\"\"\n",
    "        rel_path = src_path.relative_to(root_path)\n",
    "        dest_path = output_dir / 'audio' / rel_path\n",
    "\n",
    "        # For FLAC files, we'll convert to WAV\n",
    "        if audio_type == 'flac':\n",
    "            dest_path = dest_path.with_suffix('.wav')\n",
    "        \n",
    "        dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Only process if file doesn't exist\n",
    "        if not dest_path.exists():\n",
    "            if audio_type == 'flac':\n",
    "                # Read FLAC and write as WAV\n",
    "                audio_data, samplerate = sf.read(str(src_path))\n",
    "                sf.write(str(dest_path), audio_data, samplerate)\n",
    "            else:\n",
    "                # Direct copy for WAV files\n",
    "                shutil.copy2(src_path, dest_path)\n",
    "        \n",
    "        return dest_path\n",
    "\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>VPC Dataset Report</title>\n",
    "        <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "        <style>\n",
    "            .audio-cell {{ width: 250px; }}\n",
    "            .audio-player {{ width: 100%; }}\n",
    "            .error {{ color: red; }}\n",
    "            .meta-data {{ font-size: 0.9em; color: #666; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body class=\"container-fluid p-4\">\n",
    "        <h1>VPC Dataset Report</h1>\n",
    "        <div class=\"row mb-4\">\n",
    "            <div class=\"col\">\n",
    "                <div class=\"card\">\n",
    "                    <div class=\"card-body\">\n",
    "                        <h5 class=\"card-title\">Dataset Summary</h5>\n",
    "                        <p class=\"card-text\">Total samples: {len(df)}</p>\n",
    "                        <p class=\"card-text\">Systems analyzed: {df['system_name'].nunique() if 'system_name' in df.columns else 'N/A'}</p>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        <div class=\"table-responsive\">\n",
    "            <table class=\"table table-striped table-bordered\">\n",
    "                <thead class=\"table-light\">\n",
    "                    <tr>\n",
    "                        {' '.join(f\"<th>{COLUMN_DISPLAY_NAMES.get(col, col)}</th>\" for col in df.columns)}\n",
    "                    </tr>\n",
    "                </thead>\n",
    "                <tbody>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process rows\n",
    "    for idx, row in df.iterrows():\n",
    "        html_content += \"<tr>\"\n",
    "        for col in df.columns:\n",
    "            if col in AUDIO_ROOTS:\n",
    "                try:\n",
    "                    audio_info = AUDIO_ROOTS[col]\n",
    "                    root_path = audio_info['root']\n",
    "                    audio_type = audio_info['type']\n",
    "                    audio_path = Path(str(row[col]))\n",
    "                    \n",
    "                    if not audio_path.is_absolute():\n",
    "                        audio_path = root_path / audio_path\n",
    "                    \n",
    "                    if audio_path.is_file():\n",
    "                        # Handle the audio file (copy or convert)\n",
    "                        dest_path = handle_audio_file(audio_path, root_path, audio_type)\n",
    "                        rel_path = dest_path.relative_to(output_dir)\n",
    "                        \n",
    "                        html_content += f'''\n",
    "                            <td class=\"audio-cell\">\n",
    "                                <audio controls class=\"audio-player\">\n",
    "                                    <source src=\"{rel_path}\" type=\"audio/wav\">\n",
    "                                    Your browser does not support audio.\n",
    "                                </audio>\n",
    "                                <div class=\"meta-data mt-1\">\n",
    "                                    {COLUMN_DISPLAY_NAMES.get(col, col)}: {rel_path.name}\n",
    "                                </div>\n",
    "                            </td>\n",
    "                        '''\n",
    "                    else:\n",
    "                        html_content += f'<td class=\"error\">Audio file not found: {audio_path}</td>'\n",
    "                except Exception as e:\n",
    "                    html_content += f'<td class=\"error\">Error: {str(e)}</td>'\n",
    "            else:\n",
    "                html_content += f\"<td>{row[col]}</td>\"\n",
    "        html_content += \"</tr>\"\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "                </tbody>\n",
    "            </table>\n",
    "        </div>\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js\"></script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    output_path = output_dir / output_file\n",
    "    output_path.write_text(html_content)\n",
    "    \n",
    "    print(f\"Report generated: {output_path}\")\n",
    "    return str(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process the data\n",
    "# processed_df = process_vpc_data(num_speakers=29, num_utts_per_spk=2)\n",
    "\n",
    "# # Create the HTML report\n",
    "# report_file = create_html_report(processed_df, enrollment_root=VPC_DIR, libri_root=LIBRI_DIR)\n",
    "\n",
    "report_file = ''\n",
    "print(f\"Report generated: {report_file}\")\n",
    "print(\"To view the report, start a local server:\")\n",
    "print(\"python -m http.server 8001\")\n",
    "print(f\"Then open http://localhost:8001/{report_file} in your browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (comfort)",
   "language": "python",
   "name": "comfort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
