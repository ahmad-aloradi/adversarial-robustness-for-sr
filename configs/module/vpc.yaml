_target_: src.modules.multimodal_vpc.MultiModalVPCModel

defaults:
  - _self_

model:
  audio_processor:
    _target_: torch.nn.Identity

  audio_encoder:
    _target_: speechbrain.inference.EncoderClassifier.from_hparams
    source: "speechbrain/spkrec-ecapa-voxceleb"
    savedir: "local/.pretrained_models/spkrec-ecapa-voxceleb"
    run_opts:
      device: "cuda"

  audio_processor_kwargs:
    return_tensors: "pt"
    sampling_rate: 16000

  text_processor:
    _target_: transformers.BertTokenizer.from_pretrained
    pretrained_model_name_or_path: "bert-base-uncased"

  text_encoder:
    _target_: transformers.BertModel.from_pretrained
    pretrained_model_name_or_path: ${module.model.text_processor.pretrained_model_name_or_path}
    num_labels: ${module.model.classifiers.config.num_classes}

  text_processor_kwargs:
    return_tensors: "pt"
    padding: "max_length"
    truncation: True
    max_length: 512

  classifiers:
    # Common configuration
    config:
      num_classes: ${datamodule.num_classes}
      bottleneck_size: 512
      fusion_classifier_input_size: 512
      fusion_classifier_hidden_size: 1024
      audio_embedding_size: 192  # ECAPA embedding size
      text_embedding_size: 768   # BERT embedding size

    # Available classifier definitions
    available_classifiers:
      normalized:
        _target_: src.modules.multimodal_vpc.FixedFusionClassifierWithResiduals
        fuse_model:
          _target_: src.modules.multimodal_vpc.NormalizedWeightedSum
          audio_embedding_size: ${module.model.classifiers.config.audio_embedding_size}
          text_embedding_size: ${module.model.classifiers.config.text_embedding_size}
          bottleneck_size: ${module.model.classifiers.config.bottleneck_size}
        input_size: ${module.model.classifiers.config.fusion_classifier_input_size}
        hidden_size: ${module.model.classifiers.config.fusion_classifier_hidden_size}
        num_classes: ${module.model.classifiers.config.num_classes}
        dropout: 0.3
        norm_type: "batch"
      
      identity_gated:
        _target_: src.modules.multimodal_vpc.FixedFusionClassifierWithResiduals
        fuse_model:
          _target_: src.modules.multimodal_vpc.IdentityGatedFusion
          audio_embedding_size: ${module.model.classifiers.config.audio_embedding_size}
          text_embedding_size: ${module.model.classifiers.config.text_embedding_size}
          bottleneck_size: ${module.model.classifiers.config.bottleneck_size}
          dropout: 0.2
        input_size: ${module.model.classifiers.config.fusion_classifier_input_size}
        hidden_size: ${module.model.classifiers.config.fusion_classifier_hidden_size}
        num_classes: ${module.model.classifiers.config.num_classes}
        dropout: 0.3
        norm_type: "batch"
      
      speaker_attention:
        _target_: src.modules.multimodal_vpc.FixedFusionClassifierWithResiduals
        fuse_model:
          _target_: src.modules.multimodal_vpc.SpeakerFocusedAttention
          audio_embedding_size: ${module.model.classifiers.config.audio_embedding_size}
          text_embedding_size: ${module.model.classifiers.config.text_embedding_size}
          bottleneck_size: ${module.model.classifiers.config.bottleneck_size}
          num_heads: 4
          dropout: 0.1
        input_size: ${module.model.classifiers.config.fusion_classifier_input_size}
        hidden_size: ${module.model.classifiers.config.fusion_classifier_hidden_size}
        num_classes: ${module.model.classifiers.config.num_classes}
        dropout: 0.3
        norm_type: "batch"
      
      hierarchical:
        _target_: src.modules.multimodal_vpc.RobustHierarchicalFusion
        audio_embedding_size: ${module.model.classifiers.config.audio_embedding_size}
        text_embedding_size: ${module.model.classifiers.config.text_embedding_size}
        hidden_size: ${module.model.classifiers.config.bottleneck_size}
        num_classes: ${module.model.classifiers.config.num_classes}
        dropout: 0.3
      
      robust:
        _target_: src.modules.multimodal_vpc.RobustFusionClassifier
        audio_size: ${module.model.classifiers.config.audio_embedding_size}
        text_size: ${module.model.classifiers.config.text_embedding_size}
        hidden_size: ${module.model.classifiers.config.bottleneck_size}
        num_classes: ${module.model.classifiers.config.num_classes}
        dropout_audio: 0.3
        dropout_text: 0.1

    # Selected classifier (defaults to identity_gated)
    selected_classifier: identity_gated
    fusion_classifier: ${module.model.classifiers.available_classifiers.${module.model.classifiers.selected_classifier}}

  embedding_cache:
    max_size: 500000
    bypass_warmup: True
    
  # Enable score normalization for improved performance
  normalize_test_scores: True

criterion:
  available_criteria:
    _base_aam_: &_base_aam_
      _target_: speechbrain.nnet.losses.LogSoftmaxWrapper
      loss_fn:
        _target_: speechbrain.nnet.losses.AdditiveAngularMargin
        margin: 0.2 
        scale: 30.0
    
    stabilized:
      _target_: src.modules.multimodal_vpc.StabilizedCriterion      
      classification_loss: 
        <<: *_base_aam_
      contrastive_weight: 0.05
    
    enhanced:
      _target_: src.modules.multimodal_vpc.EnhancedCriterion      
      classification_loss: 
        <<: *_base_aam_
    
    fusion:
      _target_: src.modules.multimodal_vpc.MultiModalFusionLoss
      classification_loss: 
        <<: *_base_aam_
    
    aam:
      <<: *_base_aam_
    
    cross_entropy:
      _target_: torch.nn.CrossEntropyLoss

  # Selected criterion (defaults to stabilized)
  selected_criterion: stabilized
  train_criterion: ${module.criterion.available_criteria.${module.criterion.selected_criterion}}

  # For callbacks
  loss: ${module.criterion.train_criterion}

gradient_clip_val: 5.0

optimizer:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 1.0e-4
  weight_decay: 1.0e-5

# Use improved learning rate scheduler with warmup
lr_scheduler:
  scheduler:
    _target_: src.modules.multimodal_vpc.CosineWarmupScheduler
    warmup_epochs: 2
    max_epochs: 20
    warmup_start_lr: 1.0e-6
    eta_min: 1.0e-7
  extras:
    monitor: ${replace:"__metric__/valid"}/${module.metrics.valid_best.target_key}
    interval: "epoch"
    frequency: 1

metrics:
  train:
    _target_: "torchmetrics.Accuracy"
    task: "multiclass"
    num_classes: ${module.model.classifiers.config.num_classes}
  valid:
    _target_: src.modules.metrics.metrics.VerificationMetrics
  test:
    _target_: src.modules.metrics.metrics.VerificationMetrics
  valid_best:
    _target_: src.modules.metrics.metrics.AutoSyncDictMinMetric
    target_key: "eer"

logging_params:
  on_step: False
  on_epoch: True
  sync_dist: True
  prog_bar: True

batch_sizes:
  train: ${datamodule.loaders.train.batch_size}
  valid: ${datamodule.loaders.valid.batch_size}
  test: ${datamodule.loaders.test.batch_size}

# Add callbacks for dynamic loss weight adjustment
callbacks:
  adaptive_loss_weights:
    _target_: src.modules.multimodal_vpc.AdaptiveLossWeights
    initial_contrastive_weight: 0.05
    min_weight: 0.01  
    max_weight: 0.2
    patience: 3
    factor: 0.5
    monitor: ${replace:"__metric__/valid"}/${module.metrics.valid_best.target_key} # Monitor EER metric
    mode: "min"  # Lower EER is better