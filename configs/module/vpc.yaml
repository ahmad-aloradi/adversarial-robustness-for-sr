_target_: src.modules.multimodal_vpc.MultiModalVPCModel

defaults:
  # - network: classification.yaml
  - _self_

model:
  text_encoder:
    _target_: transformers.Wav2Vec2ForCTC.from_pretrained
    pretrained_model_name_or_path: "facebook/wav2vec2-base-960h"
    num_labels: ${module.model.classifiers.classifiers_config.num_classes}

  processor:
    _target_: transformers.Wav2Vec2Processor.from_pretrained
    pretrained_model_name_or_path: "facebook/wav2vec2-base-960h"

  audio_encoder:
    _target_: speechbrain.inference.EncoderClassifier.from_hparams
    source: "speechbrain/spkrec-xvect-voxceleb"
    savedir: "local/.pretrained_models/spkrec-xvect-voxceleb"
    run_opts: {"device":"cuda:0"}

  classifiers:
    text_classifier: 
      _target_: torch.nn.Linear
      in_features: ${module.model.classifiers.classifiers_config.text_encoder_output_dim}
      out_features: ${module.model.classifiers.classifiers_config.num_classes}

    audio_classifier: 
      _target_: torch.nn.Linear
      in_features: ${module.model.classifiers.classifiers_config.audio_encoder_output_dim}
      out_features: ${module.model.classifiers.classifiers_config.num_classes}

    gender_classifier:
      _target_: torch.nn.Sequential
      _args_:
        - _target_: torch.nn.Linear
          in_features: ${module.model.classifiers.classifiers_config.audio_encoder_output_dim}
          out_features: ${module.model.classifiers.classifiers_config.gender_out_features}
        - _target_: torch.nn.ReLU
        - _target_: torch.nn.Dropout
          p: 0.2
        - _target_: torch.nn.Linear
          in_features: ${module.model.classifiers.classifiers_config.gender_out_features}
          out_features: 1

    classifiers_config:
      num_classes: 921 # 7205
      text_encoder_output_dim: 32
      audio_encoder_output_dim: 512
      gender_out_features: 256

criterion:

  _base_text_criterion:
    _target_: torch.nn.CrossEntropyLoss

  _base_audio_criterion:
    _target_: torch.nn.CrossEntropyLoss
    label_smoothing: 0.1

  _base_gender_criterion:
    _target_: torch.nn.BCEWithLogitsLoss

  criterion_train:
    text_criterion: ${module.criterion._base_text_criterion}
    audio_criterion: ${module.criterion._base_audio_criterion}
    gender_criterion: ${module.criterion._base_gender_criterion}

  criterion_val:
    text_criterion: ${module.criterion._base_text_criterion}
    audio_criterion: ${module.criterion._base_audio_criterion}
    gender_criterion: ${module.criterion._base_gender_criterion}

  criterion_test:
    text_criterion: ${module.criterion._base_text_criterion}
    audio_criterion: ${module.criterion._base_audio_criterion}
    gender_criterion: ${module.criterion._base_gender_criterion}

  loss_weights:
    text: 0.15
    audio: 0.8
    gender: 0.05
    
  loss: ${module.criterion._base_audio_criterion} # for callbacks

optimizer:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 3.0e-4
  weight_decay: 1.0e-5

lr_scheduler:
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    mode: "max"
    factor: 0.3
    min_lr: 1.0e-9
    patience: 4
    verbose: True
  extras:
    monitor: ${replace:"__metric__/valid"}
    interval: "epoch"
    frequency: 1

metrics:
  main:
    _target_: "torchmetrics.Accuracy"
    task: "multiclass"
    num_classes: ${module.model.classifiers.classifiers_config.num_classes}
  valid_best:
    _target_: "torchmetrics.MaxMetric"
  additional:
    AUROC:
      _target_: "torchmetrics.AUROC"
      task: "binary"

logging_params:
  on_step: False
  on_epoch: True
  sync_dist: True
  prog_bar: True

batch_sizes:
  train: ${datamodule.loaders.train.batch_size}
  valid: ${datamodule.loaders.valid.batch_size}
  test: ${datamodule.loaders.test.batch_size}