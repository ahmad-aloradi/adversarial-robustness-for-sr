_target_: src.modules.multimodal_vpc.MultiModalVPCModel

defaults:
  - _self_

### Data for augmentation ###
# data_augemntation:

#   noise_dataset_url: https://www.dropbox.com/scl/fi/a09pj97s5ifan81dqhi4n/noises.zip?rlkey=j8b0n9kdjdr32o1f06t0cw5b7&dl=1
#   rir_dataset_url: https://www.dropbox.com/scl/fi/linhy77c36mu10965a836/RIRs.zip?rlkey=pg9cu8vrpn2u173vhiqyu743u&dl=1
#   data_folder_rir_noises: ${paths.data_dir}/RIRS_NOISES
#   noise_annotation: ${module.data_augemntation.data_folder_rir_noises}/noise.csv
#   rir_annotation: ${module.data_augemntation.data_folder_rir_noises}/reverb.csv

#   data:
#     noise_dataset:
#       _target_: speechbrain.augment.preparation.prepare_dataset_from_URL
#       URL: ${module.data_augemntation.noise_dataset_url}
#       dest_folder: ${module.data_augemntation.data_folder_rir_noises}
#       ext: wav
#       csv_file: ${module.data_augemntation.noise_annotation}

#   augmentations:
#     add_noise:
#       _target_: speechbrain.augment.time_domain.AddNoise
#       csv_file: ${module.data_augemntation.noise_annotation}
#       snr_low: 0
#       snr_high: 15
#       noise_sample_rate: ${datamodule.dataset.sample_rate}
#       clean_sample_rate: ${datamodule.dataset.sample_rate}
#       num_workers: ${datamodule.loaders.train.num_workers}

#     prepare_rir:
#       _target_: speechbrain.augment.preparation.prepare_dataset_from_URL
#       URL: ${module.data_augemntation.rir_dataset_url}
#       dest_folder: ${module.data_augemntation.data_folder_rir_noises}
#       ext: wav
#       csv_file: ${module.data_augemntation.rir_annotation}

#     add_reverb:
#       _target_: speechbrain.augment.time_domain.AddReverb
#       csv_file: ${module.data_augemntation.rir_annotation}
#       reverb_sample_rate: ${datamodule.dataset.sample_rate}
#       clean_sample_rate: ${datamodule.dataset.sample_rate}
#       num_workers: ${datamodule.loaders.train.num_workers}

#     drop_freq:
#       _target_: speechbrain.augment.time_domain.DropFreq
#       drop_freq_low: 0
#       drop_freq_high: 1
#       drop_freq_count_low: 1
#       drop_freq_count_high: 3
#       drop_freq_width: 0.05

#     drop_chunk:
#       _target_: speechbrain.augment.time_domain.DropChunk
#       drop_length_low: 1000
#       drop_length_high: 2000
#       drop_count_low: 1
#       drop_count_high: 5

#     wav_augmenter:
#       _target_: speechbrain.augment.augmenter.Augmenter
#       parallel_augment: true
#       concat_original: true
#       min_augmentations: 4
#       max_augmentations: 4
#       augment_prob: 1.0
#       augmentations:
#         - ${module.data_augemntation.augmentations.add_noise}
#         - ${module.data_augemntation.augmentations.add_reverb}
#         - ${module.data_augemntation.augmentations.drop_freq}
#         - ${module.data_augemntation.augmentations.drop_chunk}


model:
  audio_processor:
    _target_: torch.nn.Identity

  audio_encoder:
    _target_: speechbrain.inference.EncoderClassifier.from_hparams
    source: "speechbrain/spkrec-ecapa-voxceleb"
    savedir: "local/.pretrained_models/spkrec-ecapa-voxceleb"
    run_opts:
      device: "cuda"

  audio_processor_kwargs:
    return_tensors: "pt"
    sampling_rate: 16000

  text_processor:
    _target_: transformers.BertTokenizer.from_pretrained
    pretrained_model_name_or_path: "bert-base-uncased"

  text_encoder:
    _target_: transformers.BertModel.from_pretrained
    pretrained_model_name_or_path: ${module.model.text_processor.pretrained_model_name_or_path}
    num_labels: ${module.model.classifiers.config.num_classes}

  text_processor_kwargs:
    return_tensors: "pt"
    padding: "max_length"
    truncation: True
    max_length: 512

### classifiers ###
  classifiers:
    # Common configuration
    config:
      num_classes: ${datamodule.num_classes}
      bottleneck_size: 512
      fusion_classifier_hidden_size: 1024
      audio_embedding_size: 192  # ECAPA embedding size
      text_embedding_size: 768   # BERT embedding size

    # Available classifier definitions
    available_classifiers:
      normalized:
        _target_: src.modules.multimodal_vpc.FusionClassifierWithResiduals
        fuse_model:
          _target_: src.modules.multimodal_vpc.NormalizedWeightedSum
          audio_embedding_size: ${module.model.classifiers.config.audio_embedding_size}
          text_embedding_size: ${module.model.classifiers.config.text_embedding_size}
          hidden_size: ${module.model.classifiers.config.bottleneck_size}
        input_size: ${module.model.classifiers.config.bottleneck_size}
        hidden_size: ${module.model.classifiers.config.fusion_classifier_hidden_size}
        num_classes: ${module.model.classifiers.config.num_classes}
        dropout_residual: 0.3
        num_residuals: 2
        norm_type: 'batch'
            
      robust:
        _target_: src.modules.multimodal_vpc.RobustFusionClassifier
        audio_embedding_size: ${module.model.classifiers.config.audio_embedding_size}
        text_embedding_size: ${module.model.classifiers.config.text_embedding_size}
        hidden_size: ${module.model.classifiers.config.bottleneck_size}
        num_classes: ${module.model.classifiers.config.num_classes}
        norm_type: 'layer'
        accum_method: 'concat'
        dropout_audio: 0.3
        dropout_text: 0.1

    # Selected classifier (defaults to robust)
    selected_classifier: ???
    fusion_classifier: ${module.model.classifiers.available_classifiers.${module.model.classifiers.selected_classifier}}

### caching ###
  embedding_cache:
    max_size: 500000
    bypass_warmup: True
    
### criteria and metrics ###
criterion:
  available_criteria:
    _base_aam_: &_base_aam_
      _target_: speechbrain.nnet.losses.LogSoftmaxWrapper
      loss_fn:
        _target_: speechbrain.nnet.losses.AdditiveAngularMargin
        margin: 0.2
        scale: 30.0

    comprehensive:
      _target_: src.modules.multimodal_vpc.MultiModalLoss
      classifier_name: ${module.model.classifiers.selected_classifier}
      weights:
        _target_: src.modules.multimodal_vpc.LossWeights
        ensemble: ${map:${module.model.classifiers.selected_classifier},robust,1.0,0.0}
        fusion: ${map:${module.model.classifiers.selected_classifier},normalized,1.0,0.2}
        audio: 0.2
        text: 0.2
        contrastive: 0.1
        consistency: 1.0
        confidence: 0.1
      confidence_target: 0.9
      classification_loss: 
        <<: *_base_aam_
    
    aam:
      <<: *_base_aam_
    
    cross_entropy:
      _target_: torch.nn.CrossEntropyLoss

  # Selected criterion (defaults to comprehensive)
  selected_criterion: ???
  train_criterion: ${module.criterion.available_criteria.${module.criterion.selected_criterion}}

  # For callbacks
  loss: ${module.criterion.train_criterion}

metrics:
  train:
    _target_: "torchmetrics.Accuracy"
    task: "multiclass"
    num_classes: ${module.model.classifiers.config.num_classes}
  valid:
    _target_: src.modules.metrics.metrics.VerificationMetrics
  test:
    _target_: src.modules.metrics.metrics.VerificationMetrics
  valid_best:
    _target_: src.modules.metrics.metrics.AutoSyncDictMinMetric
    target_key: "eer"

### optimizer and lr_scheduler ###

optimizer:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 1.0e-4
  weight_decay: 1.0e-5

scheduler_settings:
  available_lr_scheduler:
    warmup_cosine:
      _target_: torch.optim.lr_scheduler.SequentialLR
      schedulers:
        - _target_: torch.optim.lr_scheduler.LinearLR
          start_factor: 0.1
          total_iters: ${int:${mul:${trainer.max_epochs},0.1}}
        - _target_: torch.optim.lr_scheduler.CosineAnnealingLR
          T_max: ${int:${sub:${trainer.max_epochs},${module.scheduler_settings.available_lr_scheduler.warmup_cosine.schedulers[0].total_iters}}} # Remaining epochs after linear warmup
          eta_min: ${mul:${module.optimizer.lr},0.05}
      milestones:
        - ${int:${mul:${trainer.max_epochs},0.1}}  # 10% of total epochs are used for linear warmup, remaining for cosine annealing
      extras:
        monitor: valid/${replace:"__metric__"}/${module.metrics.valid_best.target_key}
        interval: epoch
        frequency: 1

    reduce_on_plateau:
      scheduler:
        _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
        mode: "min"
        factor: 0.3
        min_lr: 1.0e-7
        patience: 2
        verbose: True
      extras:
        monitor: valid/${replace:"__metric__"}/${module.metrics.valid_best.target_key}
        interval: "epoch"
        frequency: 1

  # Selected scheduler (defaults to reduce_on_plateau)
  selected_lr_scheduler: ???

lr_scheduler: ${module.scheduler_settings.available_lr_scheduler.${module.scheduler_settings.selected_lr_scheduler}}

### extras and callbacks ###
logging_params:
  on_step: False
  on_epoch: True
  sync_dist: True
  prog_bar: True

batch_sizes:
  train: ${datamodule.loaders.train.batch_size}
  valid: ${datamodule.loaders.valid.batch_size}
  test: ${datamodule.loaders.test.batch_size}

### score normalization ###
normalize_test_scores: ???   # apply score normalization or not
scores_norm:
  embeds_metric_params:
    cohort_per_model: 40000
  scores_norm_params:
    topk: 10000
    min_cohort_size: 3000
