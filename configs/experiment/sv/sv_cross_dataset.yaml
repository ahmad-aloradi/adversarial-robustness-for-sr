# @package _global_

# Cross-dataset speaker verification experiment
# Example usage:
#   python train.py experiment=sv_cross_dataset

defaults:
  - /module/sv_model: speechbrain_ecapa_tdnn.yaml
  - override /callbacks: default.yaml
  - override /datamodule: multi_sv.yaml
  - override /module: sv.yaml
  - override /trainer: gpu.yaml
  - override /logger: tensorboard.yaml


# Example seed and tags
seed: 42
tags: ["sv", "cross_dataset"]

trainer:
  min_epochs: 10
  max_epochs: 20
  gradient_clip_val: 1.0
  num_sanity_val_steps: 0

callbacks:
  model_checkpoint:
    mode: max
    monitor: ${replace:"valid/__metric__"}
  early_stopping:
    mode: max
    monitor: ${replace:"valid/__metric__"}
    patience: 8

# Datamodule overrides for typical cross-dataset usage.
datamodule:
  datasets:
    voxceleb:
      stages:
        train: true
        val: true
        test: true
    cnceleb:
      stages:
        train: false
        val: false
        test: true
  loaders:
    train:
      batch_size: 16
    valid:
      batch_size: 16
    test:
      batch_size: 8
    enrollment:
      batch_size: 8

module:
  normalize_test_scores: true

  lr_scheduler:
    scheduler:
      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
      mode: "max"
      factor: 0.25
      min_lr: 1.0e-6
      patience: 2
      verbose: true
    extras:
      monitor: ${replace:"valid/__metric__"}
      interval: "epoch"
      frequency: 1

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 1.0e-4
    weight_decay: 1.0e-5

logger:
  wandb:
    tags: ${tags}
    group: "cross_dataset"
